{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating your Dataset and loading to Hugging Face ü§ó\n",
    "\n",
    "Supported formats\n",
    "- CSV\n",
    "- JSON\n",
    "- JSON lines\n",
    "- text\n",
    "- Parquet\n",
    "- Compressed files (GZ, BZ2, LZ4, LZMA or ZSTD)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [HfApi üåê](https://huggingface.co/docs/huggingface_hub/guides/overview)\n",
    "\n",
    "```bash \n",
    "pip install --upgrade huggingface_hub\n",
    "\n",
    "```\n",
    "#### Git vs HTTP paradigm\n",
    "[**Git**](https://huggingface.co/docs/datasets/v2.13.0/share)\n",
    "\n",
    "Maintain a local copy of the entire repository on your machine\n",
    " - Training a model on your machine and pushing regular updates\n",
    " - if you need to manually edit large files\n",
    "\n",
    "**HfApi**\n",
    "\n",
    "The same functionality as git-based approaches, but without the need for a local folder\n",
    " - Managing repos\n",
    " - Downloading files using caching\n",
    " - Searching the Hub for repos and metadata\n",
    " - Accessing community features \n",
    " - Configuring Spaces hardware and secrets\n",
    "\n",
    "> **Note:** Each repo with large files (>5GB) need to install a custom transfer agent for Git LFS\n",
    ">```bash\n",
    ">huggingface-cli lfs-enable-largefiles\n",
    "\n",
    "Login\n",
    "```bash \n",
    "pip install ipywidgets\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import create_repo\n",
    "create_repo(\"Einstellung/demo-salaries\", repo_type=\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "api = HfApi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"dataset/ds_salaries.csv\",\n",
    "    path_in_repo=\"ds_salaries.csv\",\n",
    "    repo_id=\"Einstellung/demo-salaries\",\n",
    "    repo_type=\"dataset\",\n",
    "    commit_message=\"my first commit in HG\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## README.md üìÑ\n",
    "\n",
    "- [DataCard Metadata](https://github.com/huggingface/hub-docs/blob/main/datasetcard.md?plain=1)\n",
    "- [DataCard Guide](https://github.com/huggingface/datasets/blob/main/templates/README_guide.md)\n",
    "- [DataCard Template](https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/templates/datasetcard_template.md?plain=1)\n",
    "- [Valid Licenses](https://huggingface.co/docs/hub/repositories-licenses)\n",
    "- [Valid Tasks/Sub-Tasks](https://github.com/huggingface/hub-docs/blob/main/js/src/lib/interfaces/Types.ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"README.md\",\n",
    "    path_in_repo=\"README.md\",\n",
    "    repo_id=\"Einstellung/demo-salaries\",\n",
    "    repo_type=\"dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.delete_file(path_in_repo='/README.md', repo_id='Einstellung/demo-salaries', repo_type='dataset')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Folder-Based builder](https://huggingface.co/docs/datasets/create_dataset#folderbased-builders)\n",
    "- ImageFolder (jpeg, png ...)\n",
    "- AudioFolder (wav, mp3 ...)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!['builder'](img/folder-based-builder.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### metadata.csv \n",
    "The metadata file needs to have a file_name column that links the image or audio file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Loading Script üêç](https://huggingface.co/docs/datasets/v2.12.0/en/about_dataset_load#build-and-load)\n",
    "[Script Template](https://github.com/huggingface/datasets/blob/main/templates/new_dataset_script.py)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!['builder'](img/dataset_classes.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Attribute | Description |\n",
    "|---|---|\n",
    "| name | Short name of the dataset |\n",
    "| version | Dataset version identifier |\n",
    "| data_dir | Stores the path to a local folder containing the data files |\n",
    "| data_files | Stores paths to local data files |\n",
    "| description | Description of the dataset |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!['builder'](img/dataset_builder.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **DatasetBuilder._info** defining the dataset attributes and Features. dataset.info returns the information stored here.\n",
    "\n",
    "- **DatasetBuilder._split_generator** download data files, splits it and defines arguments for the generation process. \n",
    "    -   DownloadManager that downloads files or fetches them from your local filesystem. \n",
    "    -   DownloadManager.download_and_extract() a single URL or path, or a list/dictionary of URLs or paths\n",
    "\n",
    "    The SplitGenerator contains the name of the split, and any keyword arguments that are provided to the DatasetBuilder._generate_examples method. at least the local path to the data\n",
    "\n",
    "- **DatasetBuilder._generate_examples** reads and parses the data files for a split. Then it yields dataset examples according to the format specified in the features from DatasetBuilder._info(). The input of DatasetBuilder._generate_examples is actually the filepath provided in the keyword arguments of the last method.\n",
    "\n",
    "The dataset is generated with a Python generator, which doesn‚Äôt load all the data in memory. As a result, the generator can handle large datasets. However, before the generated samples are flushed to the dataset file on disk, they are stored in an ArrowWriter buffer. This means the generated samples are written by batch. \n",
    "\n",
    "> **Note:** DEFAULT_WRITER_BATCH_SIZE attribute should not exceeding 200 MB\n",
    "\n",
    "### [Wiki-Art](https://www.kaggle.com/datasets/antoinegruson/-wikiart-all-images-120k-link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_repo(\"Einstellung/wiki_art\", repo_type=\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.upload_file(\n",
    "    path_or_fileobj=\"wiki_art.py\",\n",
    "    path_in_repo=\"wiki_art.py\",\n",
    "    repo_id=\"Einstellung/wiki_art\",\n",
    "    repo_type=\"dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.delete_file(path_in_repo='/wiki_art.py', repo_id='Einstellung/wiki_art', repo_type='dataset')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Medell√≠n AI - Meetup](https://linktr.ee/colombia_ai?utm_source=linktree_profile_share&ltsid=4da78a52-278a-45b6-9cd8-3e69c51aa19d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
